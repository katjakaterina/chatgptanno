This repository contains the data used in the paper "Using ChatGPT for Annotation of Attitude within the Appraisal Theory: Lessons Learned" by Mirela Imamovic, Silvana Deilen, Dylan Glynn and Ekaterina Lapshinova-Koltunski.

In the paper, we investigate the potential of using ChatGPT to annotate complex linguistic phenomena, such as language of evaluation, attitude
and emotion according to Appraisal Theory (Martin & WHite, 2005). For this, we automatically annotate 11 texts in English, which represent spoken popular science (TED talks), and evaluate the annotations manually. Our results show that ChatGPT has good precision in itemisation, i.e. detecting linguistic items in the text that carry evaluative meaning. However, we also find that the recall is very low. Besides that, we state that the tool fails in labeling the detected items with the correct categories on a more fine-grained level of granularity. We analyse the errors to find systematic errors related to specific categories
in the annotation scheme.

The data used in the analysis can be found in the folder 'corpus' which contains  plain texts. The analyses are contained in a table which can be found in the folder 'analyses'.

If you use the data for you analyses, please cite the following paper:

Mirela Imamovic, Silvana Deilen, Dylan Glynn and EKaterina Lapshinova-Koltunski (2024). Using ChatGPT for Annotation of Attitude within the Appraisal Theory: Lessons Learned. In Proceedings of the 18th Linguistic Annotation Workshop (LAW) co-located with EACL 2024, March 22, 2024.
